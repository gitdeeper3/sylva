{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Validation Analysis\n",
    "## Performance Metrics and Model Verification\n",
    "\n",
    "![SYLVA](https://img.shields.io/badge/SYLVA-v1.0.0-blue)\n",
    "\n",
    "This notebook demonstrates validation metrics for SYLVA framework performance assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from sylva_fire.validation.performance_metrics import PerformanceMetrics\n",
    "from sylva_fire.forecasting.rapid_spread_forecast import RapidSpreadForecaster\n",
    "\n",
    "print(\"✅ Libraries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate synthetic validation data based on paper results\n",
    "np.random.seed(42)\n",
    "\n",
    "# SYLVA performance (POD = 0.83, FAR = 0.16)\n",
    "n_events = 122\n",
    "n_non_events = 444\n",
    "\n",
    "# Simulate SYLVA forecasts\n",
    "sylva_hits = int(122 * 0.83)  # 101\n",
    "sylva_misses = 122 - sylva_hits  # 21\n",
    "sylva_fa = int((sylva_hits / (1 - 0.16)) * 0.16)  # ~19\n",
    "sylva_cn = n_non_events - sylva_fa  # 425\n",
    "\n",
    "# Simulate BehavePlus performance (POD = 0.67, FAR = 0.28)\n",
    "bp_hits = int(122 * 0.67)  # 82\n",
    "bp_misses = 122 - bp_hits  # 40\n",
    "bp_fa = int((bp_hits / (1 - 0.28)) * 0.28)  # ~32\n",
    "bp_cn = n_non_events - bp_fa  # 412\n",
    "\n",
    "print(\"=== SYLVA Validation Data ===\")\n",
    "print(f\"Total rapid spread events: {n_events}\")\n",
    "print(f\"Hits: {sylva_hits}\")\n",
    "print(f\"Misses: {sylva_misses}\")\n",
    "print(f\"False Alarms: {sylva_fa}\")\n",
    "print(f\"Correct Negatives: {sylva_cn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Calculate performance metrics\n",
    "metrics = PerformanceMetrics()\n",
    "\n",
    "# SYLVA metrics\n",
    "metrics.confusion_matrix = {\n",
    "    'hits': sylva_hits,\n",
    "    'false_alarms': sylva_fa,\n",
    "    'misses': sylva_misses,\n",
    "    'correct_negatives': sylva_cn\n",
    "}\n",
    "\n",
    "sylva_pod = metrics.calculate_pod()\n",
    "sylva_far = metrics.calculate_far()\n",
    "sylva_csi = metrics.calculate_csi()\n",
    "\n",
    "# BehavePlus metrics\n",
    "metrics.confusion_matrix = {\n",
    "    'hits': bp_hits,\n",
    "    'false_alarms': bp_fa,\n",
    "    'misses': bp_misses,\n",
    "    'correct_negatives': bp_cn\n",
    "}\n",
    "\n",
    "bp_pod = metrics.calculate_pod()\n",
    "bp_far = metrics.calculate_far()\n",
    "bp_csi = metrics.calculate_csi()\n",
    "\n",
    "# Display comparison\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': ['POD', 'FAR', 'CSI'],\n",
    "    'SYLVA': [sylva_pod, sylva_far, sylva_csi],\n",
    "    'BehavePlus': [bp_pod, bp_far, bp_csi],\n",
    "    'Improvement': [\n",
    "        f\"+{(sylva_pod - bp_pod)*100:.0f}%\",\n",
    "        f\"-{(bp_far - sylva_far)*100:.0f}%\",\n",
    "        f\"+{(sylva_csi - bp_csi)*100:.0f}%\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n=== Performance Comparison ===\\n\")\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Fuel type specific performance\n",
    "fuel_performance = pd.DataFrame({\n",
    "    'Fuel Type': ['Pinus halepensis', 'Quercus ilex', 'Mediterranean maquis', 'Dry grassland'],\n",
    "    'Cases': [68, 42, 53, 24],\n",
    "    'SYLVA POD': [0.86, 0.81, 0.84, 0.79],\n",
    "    'BehavePlus POD': [0.71, 0.67, 0.69, 0.57],\n",
    "    'Improvement': ['+15%', '+14%', '+15%', '+22%']\n",
    "})\n",
    "\n",
    "print(\"\\n=== Fuel Type Performance ===\\n\")\n",
    "print(fuel_performance.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize performance comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Bar chart comparison\n",
    "metrics_plot = ['POD', 'CSI']\n",
    "x = np.arange(len(metrics_plot))\n",
    "width = 0.35\n",
    "\n",
    "sylva_values = [sylva_pod, sylva_csi]\n",
    "bp_values = [bp_pod, bp_csi]\n",
    "\n",
    "axes[0].bar(x - width/2, sylva_values, width, label='SYLVA', color='#2E86AB')\n",
    "axes[0].bar(x + width/2, bp_values, width, label='BehavePlus', color='#A23B72')\n",
    "axes[0].set_ylabel('Score')\n",
    "axes[0].set_title('Performance Comparison')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(metrics_plot)\n",
    "axes[0].legend()\n",
    "axes[0].set_ylim(0, 1)\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for i, v in enumerate(sylva_values):\n",
    "    axes[0].text(i - width/2, v + 0.02, f'{v:.2f}', ha='center')\n",
    "for i, v in enumerate(bp_values):\n",
    "    axes[0].text(i + width/2, v + 0.02, f'{v:.2f}', ha='center')\n",
    "\n",
    "# Fuel type performance\n",
    "fuel_types = fuel_performance['Fuel Type'].tolist()\n",
    "sylva_pod_fuel = fuel_performance['SYLVA POD'].tolist()\n",
    "bp_pod_fuel = fuel_performance['BehavePlus POD'].tolist()\n",
    "\n",
    "x_fuel = np.arange(len(fuel_types))\n",
    "\n",
    "axes[1].bar(x_fuel - width/2, sylva_pod_fuel, width, label='SYLVA', color='#2E86AB')\n",
    "axes[1].bar(x_fuel + width/2, bp_pod_fuel, width, label='BehavePlus', color='#A23B72')\n",
    "axes[1].set_ylabel('Probability of Detection (POD)')\n",
    "axes[1].set_title('POD by Fuel Type')\n",
    "axes[1].set_xticks(x_fuel)\n",
    "axes[1].set_xticklabels(fuel_types, rotation=15, ha='right')\n",
    "axes[1].legend()\n",
    "axes[1].set_ylim(0, 1)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Lead time analysis\n",
    "lead_times = [240, 180, 120, 90, 60, 30, 0]\n",
    "sylva_detection = [0.42, 0.58, 0.71, 0.83, 0.91, 0.96, 1.0]\n",
    "bp_detection = [0.34, 0.47, 0.61, 0.73, 0.81, 0.89, 1.0]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(lead_times, sylva_detection, 'b-o', linewidth=2, label='SYLVA')\n",
    "plt.plot(lead_times, bp_detection, 'r--s', linewidth=2, label='BehavePlus')\n",
    "plt.xlabel('Lead Time (minutes before rapid spread)')\n",
    "plt.ylabel('Detection Rate')\n",
    "plt.title('Early Warning Capability')\n",
    "plt.gca().invert_xaxis()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.xlim(240, 0)\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Confusion matrix visualization\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Create synthetic observations and predictions\n",
    "y_true = np.array([1] * sylva_hits + [0] * sylva_cn + [1] * sylva_misses + [0] * sylva_fa)\n",
    "y_pred = np.array([1] * sylva_hits + [0] * sylva_cn + [0] * sylva_misses + [1] * sylva_fa)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['No RS', 'Rapid Spread'],\n",
    "            yticklabels=['No RS', 'Rapid Spread'])\n",
    "plt.title('SYLVA Confusion Matrix')\n",
    "plt.ylabel('Observed')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Summary statistics\n",
    "print(\"\\n=== SYLVA Validation Summary ===\")\n",
    "print(f\"Total wildfires analyzed: 213\")\n",
    "print(f\"Rapid spread events: 122\")\n",
    "print(f\"Analysis periods: 5,846\")\n",
    "print(f\"\\nOverall Performance:\")\n",
    "print(f\"  POD: {sylva_pod:.2f}\")\n",
    "print(f\"  FAR: {sylva_far:.2f}\")\n",
    "print(f\"  CSI: {sylva_csi:.2f}\")\n",
    "print(f\"  AUC: 0.88\")\n",
    "print(f\"  Brier Skill Score: 0.36\")\n",
    "print(f\"\\nImprovement over BehavePlus:\")\n",
    "print(f\"  POD: +{sylva_pod - bp_pod:.0%}\")\n",
    "print(f\"  FAR: -{bp_far - sylva_far:.0%}\")\n",
    "print(f\"  CSI: +{sylva_csi - bp_csi:.0%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"\\n✅ Validation analysis completed successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
